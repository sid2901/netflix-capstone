{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51f9053",
   "metadata": {},
   "source": [
    "# üéì Assignment 3: Netflix Data Science Capstone\n",
    "This notebook includes:\n",
    "- Advanced EDA\n",
    "- Feature Engineering\n",
    "- Model Tuning & Evaluation\n",
    "- SHAP/LIME Interpretability\n",
    "- Streamlit + Docker Deployment Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932fef6",
   "metadata": {},
   "source": [
    "## üîç Section 1: Advanced EDA & Feature Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275579c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"netflix_titles.csv\")\n",
    "df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n",
    "df['description'] = df['description'].fillna('')\n",
    "df['country'] = df['country'].fillna('Unknown')\n",
    "\n",
    "# Correlation heatmap (only works on numeric)\n",
    "df['release_year'] = pd.to_numeric(df['release_year'], errors='coerce')\n",
    "sns.heatmap(df[['release_year']].corr(), annot=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52711171",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Section 2: Feature Engineering & Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64838e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['type'] = LabelEncoder().fit_transform(df['type'])\n",
    "df['rating'] = df['rating'].fillna('Unknown')\n",
    "df['rating_encoded'] = LabelEncoder().fit_transform(df['rating'])\n",
    "\n",
    "# Optional: feature drop or transformation\n",
    "df_model = df[['type', 'release_year', 'rating_encoded']].dropna()\n",
    "X = df_model.drop('type', axis=1)\n",
    "y = df_model['type']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee6dad",
   "metadata": {},
   "source": [
    "## ü§ñ Section 3: Model Training & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de937a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "joblib.dump(best_model, 'best_model.pkl')\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22facba",
   "metadata": {},
   "source": [
    "## üß† Section 4: SHAP Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff7051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(best_model, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a2315",
   "metadata": {},
   "source": [
    "## üöÄ Section 5: Streamlit + Docker Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dba859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To use in Streamlit:\n",
    "# model = joblib.load(\"best_model.pkl\")\n",
    "# prediction = model.predict([[year, rating_encoded]])\n",
    "\n",
    "# Dockerfile sample:\n",
    "# ------------------\n",
    "# FROM python:3.10\n",
    "# COPY . /app\n",
    "# WORKDIR /app\n",
    "# RUN pip install -r requirements.txt\n",
    "# EXPOSE 8501\n",
    "# CMD [\"streamlit\", \"run\", \"streamlit_app.py\"]\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
